人工智慧（AI）快速發展，應用層面也愈來愈廣，但受到科幻片影響，人們對AI機器人看法兩極，或認為它會是供人類使役的忠僕，或擔憂它成為「魔鬼終結者」（The Terminator），最終會反噬人類。已故英國物理學家霍金就曾說：「在人類文明史上，AI的發明可能是最重大事件，也有可能是最可怕事件，只是我們現在還不知道。」霍金對所謂「通用人工智慧」（AGI）的威脅憂心忡忡，認為其若發展完成，可能使人類滅絕。AGI並非那種僅針對一個或幾個任務而設計的AI程序，而是指可以自我進化的AI程序，在科幻片的想像中甚至成了會獨立思考的機器人。也許出自這種深層恐懼，美國科幻作家阿西莫夫（Isaac Asimov）在他的小說裡制定了有名的「機器人三定律」，包括機器人不得傷害人類，或任人受到傷害而袖手旁觀等，欲藉此維護人類的安全。然而在電影《機械公敵》（I, Robot）中，卻出現可不受三定律限制的AI機器人，不但會傷害人類，甚至欲統治世界。所謂「機器人三定律」，本來就只是基於想像科技訂出來的，現在隨著機器人技術越來越進步，AI技術進化，這些定律的侷限性已顯而易見，研發國防或軍事戰爭用的機器人，便根本背離了這三大法則。當AI這項用意良善的科技，即將成為殺人武器時，便牴觸了不少科學家的界線。全球30個國家及地區、逾60名專家本月4日就向南韓科學重鎮「韓國科學技術院」（KAIST）提出抗議，不滿其與大型軍工廠商合作設置研究所，研發戰爭機器人。眾專家明言，假如該院不停止研發計劃，便會拒絕往後一切合作。今年2月開始，韓國科學技術院與研發製造集束炸彈的軍工大廠「韓華集團」（Hanwha Systems）合作，共同設置研究中心，進行作戰指揮、目標追蹤、海上無人運送系統的技術研發。後來面對全球學界的抵制，該院院長申興哲（音譯）極力澄清絕未開發殺人機器，「絕不會做出違反人性尊嚴及傷害人類的研發計畫。」最近美國網路巨擘谷歌也爆出參與五角大廈的「Maven計畫」，該計畫旨在強化軍事武器的學習能力，包括利用AI影像解析技術改善無人機攻擊。消息傳出後，谷歌員工發起連署抗議，呼籲執行長皮查伊退出計畫，並承諾永不打造任何戰爭科技。但是，支持AI軍事化者仍大有人在。美國國防部政策創新資深顧問馬庫塞（Joshua Marcuse）最近表示，研發「自主武器」（即俗稱的殺人機器人）不是為了取代人類，而是要提升人類做出更優、更準確的能力和速度，自主武器若使用得當，可降低戰爭中的平民死傷。馬庫塞力促美國加速「軍事智慧化」，主要還是擔憂大陸在這方面的挑戰競爭。他指出，美國雖然設立了國防創新部門，但知識界和企業界的創新成果產業化、以及被軍隊採用的速度太慢；與之相反，「中國軍民融合的軍事創新模式比美國更具優勢」。(中國時報)